// DO NOT EDIT. AUTOGENERATED BY 'rv-runtime-generator'
.attribute arch, "rv64gc"
.section .data
boot_idx:
    // Variable for determining boot id
    .dword 0

.section .data
bss_init_done:
    // Variable for indicating bss clearing status
    .dword 0

.section .data
tp_block:
    // Thread pointer block storage
    .rept 40
    .dword 0
    .endr

.section .text.entry, "ax"
.global _start
_start:
    // The component that uses this lib needs to provide 'my_custom_reset' in its own .S file
    la t4, my_custom_reset
    jalr ra, t4, 0
    // Determine boot id
    la t6, boot_idx
    li t4, 1
    amoadd.d t6, t4, (t6)
    // Park hart if boot id is greater than max hart count defined in configuration
    li t4, 4
    bltu t6, t4, 1f
    la t3, _park_hart
    jr t3
1:
    // Read hart id
    csrr t5, mhartid
    // Initialize stack pointer using boot id
    li t3, 8192
    mul t3, t3, t6
    la sp, _stack_top
    sub sp, sp, t3
    // Zero out interrupt/exception CSRs
    csrw mie, zero
    csrw mideleg, zero
    csrw medeleg, zero
    // Default action is to park hart on return from Rust code, unless epc is changed by the called code
    la t3, _park_hart
    csrw mepc, t3
    // Default action is to return back to current mode on return from Rust code, unless changed by called code
    li t3, 6144
    csrc mstatus, t3
    li t3, 6144
    csrs mstatus, t3
    // Initialize trap vector base address
    la t3, handle_trap
    csrw mtvec, t3
    // Initialize scratch pointer with thread pointer block storage to make the return path same as trap return
    la tp, tp_block
    li t3, 80
    mul t3, t3, t6
    add tp, tp, t3
    sd t6, 32(tp)
    sd t5, 40(tp)
    csrw mscratch, tp
    // Store current stack pointer as interrupted and current mode stack pointer in thread pointer block to make return path same as trap return
    sd sp, 8(tp)
    sd sp, (tp)
    // Clear out RT state (flags) in tpblock
    sd zero, 64(tp)
    // Set FS to Clean
    csrr t3, mstatus
    li t4, 18446744073709527039
    and t3, t3, t4
    li t4, 16384
    or t3, t3, t4
    csrw mstatus, t3
    // Clear FCSR
    csrw fcsr, zero
    // Zero the FP registers
    fmv.d.x f0, zero
    fmv.d.x f1, zero
    fmv.d.x f2, zero
    fmv.d.x f3, zero
    fmv.d.x f4, zero
    fmv.d.x f5, zero
    fmv.d.x f6, zero
    fmv.d.x f7, zero
    fmv.d.x f8, zero
    fmv.d.x f9, zero
    fmv.d.x f10, zero
    fmv.d.x f11, zero
    fmv.d.x f12, zero
    fmv.d.x f13, zero
    fmv.d.x f14, zero
    fmv.d.x f15, zero
    fmv.d.x f16, zero
    fmv.d.x f17, zero
    fmv.d.x f18, zero
    fmv.d.x f19, zero
    fmv.d.x f20, zero
    fmv.d.x f21, zero
    fmv.d.x f22, zero
    fmv.d.x f23, zero
    fmv.d.x f24, zero
    fmv.d.x f25, zero
    fmv.d.x f26, zero
    fmv.d.x f27, zero
    fmv.d.x f28, zero
    fmv.d.x f29, zero
    fmv.d.x f30, zero
    fmv.d.x f31, zero
    // Jump to non-boot hart handling
    beqz t6, 2f
    la t4, _secondary_start
    jr t4
2:
    // Zero out BSS
    la t4, _sbss
    la t3, _ebss
    bgeu t4, t3, 4f
3:
    sd zero, (t4)
    addi t4, t4, 8
    bltu t4, t3, 3b
4:
    // Mark BSS init done
    la t3, bss_init_done
    li t4, 1
    sd t4, (t3)
    // Jump to Rust entrypoint on boot hart
    // Write out the Rust entrypoint address in thread pointer block
    la t4, main
    sd t4, 24(tp)
    j jump_to_rust

    .align 4
_secondary_start:
    // Wait for BSS init done
    la t4, bss_init_done
5:
    ld t3, (t4)
    beqz t3, 5b
    // Jump to Rust entrypoint on non-boot hart
    // Write out the Rust entrypoint address in thread pointer block
    la t3, secondary_main
    sd t3, 24(tp)
    j jump_to_rust

    .align 4
    .section .text, "ax"
    .global _park_hart
_park_hart:
    wfi
    j _park_hart

    .align 4
    .section .text, "ax"
restore_trap_frame:
    // Check if returning to lower privilege mode
    ld t6, 504(sp)
    li t5, 6144
    and t6, t6, t5
    beq t6, t5, 6f
    // Save unwound stack pointer in thread block structure if returning to lower privilege mode
    // The size = 560: size of trap frame 560 being aligned up to 16 bytes since we aligned sp down to be 16-byte aligned in jump_to_rust
    addi t6, sp, 560
    sd t6, (tp)
    csrw mscratch, tp
6:
    // Restore previous trapframe address to thread pointer block if rt_flags say so (bit 0)
    ld t6, 544(sp)
    andi t6, t6, 1
    beqz t6, 7f
    ld t6, 552(sp)
    sd t6, 72(tp)
    // Now restore floating point registers if required
    ld t6, 544(sp)
    andi t6, t6, 2
    beqz t6, 8f
    fld f0, 248(sp)
    fld f1, 256(sp)
    fld f2, 264(sp)
    fld f3, 272(sp)
    fld f4, 280(sp)
    fld f5, 288(sp)
    fld f6, 296(sp)
    fld f7, 304(sp)
    fld f8, 312(sp)
    fld f9, 320(sp)
    fld f10, 328(sp)
    fld f11, 336(sp)
    fld f12, 344(sp)
    fld f13, 352(sp)
    fld f14, 360(sp)
    fld f15, 368(sp)
    fld f16, 376(sp)
    fld f17, 384(sp)
    fld f18, 392(sp)
    fld f19, 400(sp)
    fld f20, 408(sp)
    fld f21, 416(sp)
    fld f22, 424(sp)
    fld f23, 432(sp)
    fld f24, 440(sp)
    fld f25, 448(sp)
    fld f26, 456(sp)
    fld f27, 464(sp)
    fld f28, 472(sp)
    fld f29, 480(sp)
    fld f30, 488(sp)
    fld f31, 496(sp)
    ld t6, 544(sp)
    andi t6, t6, -3
    sd t6, 544(sp)
8:
7:
    // Restore all CSRs first since they require a general register for csrw
    ld t6, 504(sp)
    csrw mstatus, t6
    ld t6, 512(sp)
    csrw mepc, t6
    ld t6, 536(sp)
    csrw fcsr, t6
    // Now restore all general registers except sp - sp is restored last
    ld ra, (sp)
    // Clear any reservations before performing a context switch
    sc.d zero, ra, (sp)
    ld gp, 16(sp)
    ld tp, 24(sp)
    ld t0, 32(sp)
    ld t1, 40(sp)
    ld t2, 48(sp)
    ld s0, 56(sp)
    ld s1, 64(sp)
    ld a0, 72(sp)
    ld a1, 80(sp)
    ld a2, 88(sp)
    ld a3, 96(sp)
    ld a4, 104(sp)
    ld a5, 112(sp)
    ld a6, 120(sp)
    ld a7, 128(sp)
    ld s2, 136(sp)
    ld s3, 144(sp)
    ld s4, 152(sp)
    ld s5, 160(sp)
    ld s6, 168(sp)
    ld s7, 176(sp)
    ld s8, 184(sp)
    ld s9, 192(sp)
    ld s10, 200(sp)
    ld s11, 208(sp)
    ld t3, 216(sp)
    ld t4, 224(sp)
    ld t5, 232(sp)
    ld t6, 240(sp)
    // Restore sp and perform return from mode
    ld sp, 8(sp)
    mret

    .align 4
    .section .text, "ax"
handle_trap:
    // Check if this is a nested trap. If yes, then scratch would be 0
    csrrw tp, mscratch, tp
    bnez tp, 9f
    // For nested trap, read back tp from scratch
    csrr tp, mscratch
    // Store current stack pointer as current mode stack to use
    sd sp, (tp)
    // Set rt state(flags) to indicate we are in nested mode. No free reg to use. So, let's use sp and restore it back from tpblock.
    addi sp, zero, 1
    sd sp, 64(tp)
    ld sp, (tp)
    j 10f
9:
    // Not in recursive trap. Clear out rt flags in tp block
    // Clear out RT state (flags) in tpblock
    sd zero, 64(tp)
10:
    // Store current stack pointer as interrupted mode stack pointer to restore on return path
    sd sp, 8(tp)
    csrr sp, mscratch
    sd sp, 16(tp)
    // We only have SP register available to use as temp reg to stash Rust entrypoint
    // Write out the Rust entrypoint address in thread pointer block
    la sp, trap_enter
    sd sp, 24(tp)
    // Load current mode stack pointer to start using stack in current mode
    ld sp, (tp)
    j jump_to_rust

    .align 4
    .section .text, "ax"
jump_to_rust:
    // save RA before we lose it due to jal
    sd ra, 56(tp)
    jal create_trap_frame
    // Set up global pointer
    .option push
    .option norelax
    la gp, _global_pointer
    .option pop
    // Store trap frame address (current sp value) in tpblock
    sd sp, 72(tp)
    // On return from Rust, goto restore_trap_frame
    ld t6, 24(tp)
    la ra, restore_trap_frame
    jr t6

    .align 4
    // Function to be called from non-assembly code
    .section .text, "ax"
    .global __my_boot_id
__my_boot_id:
    // Take id from tp block and place it in a0 as return value
    ld a0, 32(tp)
    // Return back to address in ra
    jr ra

    .align 4
    // Function to be called from non-assembly code
    .section .text, "ax"
    .global __my_hart_id
__my_hart_id:
    // Take id from tp block and place it in a0 as return value
    ld a0, 40(tp)
    // Return back to address in ra
    jr ra

    .align 4
    // Function to be called from non-assembly code
    .section .text, "ax"
    .global __my_trap_frame_addr
__my_trap_frame_addr:
    // Take trap frame addr from tp block and place it in a0 as return value
    ld a0, 72(tp)
    // Return back to address in ra
    jr ra

    .align 4
    // Function to be called from non-assembly code
    .section .text, "ax"
    .global __my_tpblock_addr
__my_tpblock_addr:
    // Take tp block address from tp and place it in a0 as return value
    add a0, tp, zero
    // Return back to address in ra
    jr ra

    .align 4
    // Function to be called from non-assembly code
    .section .text, "ax"
    .global __tpblock_base
__tpblock_base:
    // Load address of tp block in a0 as return value
    la a0, tp_block
    // Return back to address in ra
    jr ra

    .align 4
    // Function to be called from non-assembly code
    .section .text, "ax"
    .global __get_restore_tf_label
__get_restore_tf_label:
    // Load address of rest tf in a0 as return value
    la a0, restore_trap_frame
    // Return back to address in ra
    jr ra

    .align 4
    .section .text, "ax"
    .global __switch_to
__switch_to:
    // input: a0 contains address of the thread block to switch to
    // save interrupted registers first
    sd sp, 8(tp)
    sd tp, 16(tp)
    // We want to return back to ra, so set it as mepc
    csrw mepc, ra
    // Write ra to tpblock.return_address so that it is saved correctly
    sd ra, 56(tp)
    // Set RT flag to indicate that trapframe address must be restored on switching back to this context
    addi sp, zero, 1
    sd sp, 64(tp)
    ld sp, 8(tp)
    // save current context now
    jal create_trap_frame
    // Save just created frame to priv mode context
    ld t6, 48(tp)
    sd sp, (t6)
    // Store priv mode context (passed in a0) as current context
    sd a0, 48(tp)
    // Zero out current mode sp in TpBlock since we are switching threads
    // this gets initialized on trap exit to lower mode and nested trap entry paths.
    sd zero, (tp)
    // Switch priv context to the one provided in a0
    ld sp, (a0)
    // Zero out priv context frame address in context being switched to since we are restoring it now
    sd zero, (a0)
    // some task are hart agnostic. Make sure when they resume
    // they get to run with tp of the hart that invoked them
    sd tp, 24(sp)
    j restore_trap_frame
    // Create new trapframe

    .align 4
    .section .text, "ax"
create_trap_frame:
    addi sp, sp, -560
    // Align sp down to ensure it is 16-byte aligned by performing andi sp, sp, ~0xf. This is required by the spec
    // We are doing this in two steps with the following andi instruction(instead of sub the aligned size directly)
    // since in case of nested trap, sp can not be guaranteed to be aligned upon entry.
    andi sp, sp, -16
    // First stash away all the general registers in trap frame except SP, TP and RA - those are stashed from elsewhere
    sd gp, 16(sp)
    sd t0, 32(sp)
    sd t1, 40(sp)
    sd t2, 48(sp)
    sd s0, 56(sp)
    sd s1, 64(sp)
    sd a0, 72(sp)
    sd a1, 80(sp)
    sd a2, 88(sp)
    sd a3, 96(sp)
    sd a4, 104(sp)
    sd a5, 112(sp)
    sd a6, 120(sp)
    sd a7, 128(sp)
    sd s2, 136(sp)
    sd s3, 144(sp)
    sd s4, 152(sp)
    sd s5, 160(sp)
    sd s6, 168(sp)
    sd s7, 176(sp)
    sd s8, 184(sp)
    sd s9, 192(sp)
    sd s10, 200(sp)
    sd s11, 208(sp)
    sd t3, 216(sp)
    sd t4, 224(sp)
    sd t5, 232(sp)
    sd t6, 240(sp)
    // Check if FS is dirty and if so, stash the floating-point registers
    csrr t6, mstatus
    li t4, 24576
    and t5, t6, t4
    bne t5, t4, 11f
    fsd f0, 248(sp)
    fsd f1, 256(sp)
    fsd f2, 264(sp)
    fsd f3, 272(sp)
    fsd f4, 280(sp)
    fsd f5, 288(sp)
    fsd f6, 296(sp)
    fsd f7, 304(sp)
    fsd f8, 312(sp)
    fsd f9, 320(sp)
    fsd f10, 328(sp)
    fsd f11, 336(sp)
    fsd f12, 344(sp)
    fsd f13, 352(sp)
    fsd f14, 360(sp)
    fsd f15, 368(sp)
    fsd f16, 376(sp)
    fsd f17, 384(sp)
    fsd f18, 392(sp)
    fsd f19, 400(sp)
    fsd f20, 408(sp)
    fsd f21, 416(sp)
    fsd f22, 424(sp)
    fsd f23, 432(sp)
    fsd f24, 440(sp)
    fsd f25, 448(sp)
    fsd f26, 456(sp)
    fsd f27, 464(sp)
    fsd f28, 472(sp)
    fsd f29, 480(sp)
    fsd f30, 488(sp)
    fsd f31, 496(sp)
    // Now that the FP registers are stashed, set the FS state to Clean
    xori t4, t4, -1
    and t5, t4, t6
    li t4, 16384
    or t6, t5, t4
    csrw mstatus, t6
    // Record the fact that the FP registers will need to be restored in RT flags
    ld t5, 64(tp)
    li t4, 2
    or t5, t5, t4
    sd t5, 64(tp)
11:
    // Stash SP in trap frame using the interrupted mode stack value in thread pointer block
    ld t5, 8(tp)
    sd t5, 8(sp)
    // get ra from thread pointer block and save
    ld t5, 56(tp)
    sd t5, (sp)
    // Stash TP in trap frame using the scratch register value
    ld t5, 16(tp)
    sd t5, 24(sp)
    // Write 0 to scratch register so that trap entry path knows if we encounter a nested trap in current mode
    csrw mscratch, zero
    // Stash all the CSRs in trap frame
    csrr t5, mstatus
    sd t5, 504(sp)
    csrr t5, mepc
    sd t5, 512(sp)
    csrr t5, mtval
    sd t5, 520(sp)
    csrr t5, mcause
    sd t5, 528(sp)
    csrr t5, fcsr
    sd t5, 536(sp)
    // Read RT state (flags) from tpblock and save to trapframe
    ld t5, 64(tp)
    sd t5, 544(sp)
    // Clear out RT state (flags) in tpblock
    sd zero, 64(tp)
    // Stash trap ctx frame address in current trapframe
    ld t5, 72(tp)
    sd t5, 552(sp)
    ret
